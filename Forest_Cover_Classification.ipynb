{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7mR/D/DVs5wag1fq2WYFl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Valar-Melkor/Deep-Learning-Projects/blob/main/Forest_Cover_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predicting Forest Cover**\n",
        "\n",
        "The actual forest cover type for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information System data. The covertypes are the following:\n",
        "\n",
        "\n",
        "*   Spruce/Fir\n",
        "*   Lodgepole Pine\n",
        "*   Ponderosa Pine\n",
        "*   Cottonwood/Willow\n",
        "*   Aspen\n",
        "*   Douglas-fir\n",
        "*   Krummholz\n",
        "\n",
        "\n",
        "Independent variables were then derived from data obtained from the US Geological Survey and USFS.\n",
        "\n",
        "This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so existing forest cover types are mainly a result of ecological processes rather than forest management practices.\n",
        "\n",
        "My task is to **create a deep learning model to predict the cover types(class) based on the other variables**."
      ],
      "metadata": {
        "id": "xkQQ3gMIaqRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the required libraries\n",
        "\n",
        "Tensorflow, Keras, Numpy and Pandas as well as Scikit-Learn have been utlized."
      ],
      "metadata": {
        "id": "q3vO-mJjcO8O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "TOKsxDGIuiSb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading the data \n",
        "\n",
        "Reading the data and then extracting the target variable as well as divind the the data into training and testing parts/sets."
      ],
      "metadata": {
        "id": "GA53M1hWcnpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/cover_data.csv')\n",
        "\n",
        "X = data.iloc[:, 0:-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "y = keras.utils.to_categorical(y)\n",
        "X = X.to_numpy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
        "X_train[:, 0:10]"
      ],
      "metadata": {
        "id": "sqLdaZoIu44v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1de4e07-dad5-46be-8a6e-94351c1a8ee6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2883,  169,   15, ...,  245,  142, 3319],\n",
              "       [3146,   82,   14, ...,  215,  105, 4702],\n",
              "       [3348,  233,   21, ...,  253,  205,  618],\n",
              "       ...,\n",
              "       [2689,   67,   14, ...,  212,  109, 2347],\n",
              "       [3234,  113,   23, ...,  210,   73, 4046],\n",
              "       [3045,   88,    9, ...,  226,  124,  834]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Data was almost in the correct format. One hot encoding appeared to already had been applied to the categorical features, however there was a need to scale the remaining features."
      ],
      "metadata": {
        "id": "psVxjl8uc4O5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train[:, 0:10] = scaler.fit_transform(X_train[:, 0:10])\n",
        "X_test[:, 0:10] = scaler.transform(X_test[:, 0:10])"
      ],
      "metadata": {
        "id": "i6tceiiTn1ON"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building and training the model\n",
        "\n",
        "The model consists of five layers (exclusing output layer and input layer). Accuracy and AUC were used as metrics to analyze the performance of the model, validation was also used. After tuning the model, the final model has an accuracy of 78% on training data and 77% on validation data. "
      ],
      "metadata": {
        "id": "1h1umLR1dQtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.InputLayer(input_shape = (X_train.shape[1],)))\n",
        "\n",
        "model.add(layers.Dense(1024, activation = 'relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(512, activation = 'relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(256, activation = 'relu'))\n",
        "\n",
        "model.add(layers.Dense(8, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', metrics = [keras.metrics.CategoricalAccuracy(), keras.metrics.AUC()], optimizer = keras.optimizers.Adam(learning_rate = 0.001))\n",
        "\n",
        "model.fit(X_train, y_train, epochs = 40, verbose = 1, validation_split = 0.1 , batch_size = 256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwgSPvSen2Hl",
        "outputId": "432142bf-1c5b-4ed4-94e1-76bfa202e419"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "1839/1839 [==============================] - 10s 5ms/step - loss: 0.6240 - categorical_accuracy: 0.7152 - auc_32: 0.9675 - val_loss: 0.5641 - val_categorical_accuracy: 0.7391 - val_auc_32: 0.9733\n",
            "Epoch 2/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.5565 - categorical_accuracy: 0.7442 - auc_32: 0.9737 - val_loss: 0.5391 - val_categorical_accuracy: 0.7526 - val_auc_32: 0.9752\n",
            "Epoch 3/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.5355 - categorical_accuracy: 0.7531 - auc_32: 0.9755 - val_loss: 0.5298 - val_categorical_accuracy: 0.7537 - val_auc_32: 0.9760\n",
            "Epoch 4/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.5240 - categorical_accuracy: 0.7581 - auc_32: 0.9764 - val_loss: 0.5203 - val_categorical_accuracy: 0.7594 - val_auc_32: 0.9768\n",
            "Epoch 5/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.5155 - categorical_accuracy: 0.7616 - auc_32: 0.9772 - val_loss: 0.5145 - val_categorical_accuracy: 0.7624 - val_auc_32: 0.9772\n",
            "Epoch 6/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.5093 - categorical_accuracy: 0.7636 - auc_32: 0.9776 - val_loss: 0.5085 - val_categorical_accuracy: 0.7636 - val_auc_32: 0.9777\n",
            "Epoch 7/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.5039 - categorical_accuracy: 0.7655 - auc_32: 0.9781 - val_loss: 0.5070 - val_categorical_accuracy: 0.7651 - val_auc_32: 0.9778\n",
            "Epoch 8/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4999 - categorical_accuracy: 0.7678 - auc_32: 0.9784 - val_loss: 0.5047 - val_categorical_accuracy: 0.7665 - val_auc_32: 0.9779\n",
            "Epoch 9/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4966 - categorical_accuracy: 0.7692 - auc_32: 0.9787 - val_loss: 0.5037 - val_categorical_accuracy: 0.7653 - val_auc_32: 0.9781\n",
            "Epoch 10/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4937 - categorical_accuracy: 0.7700 - auc_32: 0.9789 - val_loss: 0.5030 - val_categorical_accuracy: 0.7681 - val_auc_32: 0.9783\n",
            "Epoch 11/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4918 - categorical_accuracy: 0.7709 - auc_32: 0.9790 - val_loss: 0.5032 - val_categorical_accuracy: 0.7678 - val_auc_32: 0.9780\n",
            "Epoch 12/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4887 - categorical_accuracy: 0.7720 - auc_32: 0.9793 - val_loss: 0.5007 - val_categorical_accuracy: 0.7691 - val_auc_32: 0.9782\n",
            "Epoch 13/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4874 - categorical_accuracy: 0.7725 - auc_32: 0.9794 - val_loss: 0.5001 - val_categorical_accuracy: 0.7694 - val_auc_32: 0.9784\n",
            "Epoch 14/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4858 - categorical_accuracy: 0.7728 - auc_32: 0.9795 - val_loss: 0.4987 - val_categorical_accuracy: 0.7691 - val_auc_32: 0.9784\n",
            "Epoch 15/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4841 - categorical_accuracy: 0.7737 - auc_32: 0.9796 - val_loss: 0.4984 - val_categorical_accuracy: 0.7702 - val_auc_32: 0.9786\n",
            "Epoch 16/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4828 - categorical_accuracy: 0.7744 - auc_32: 0.9797 - val_loss: 0.4975 - val_categorical_accuracy: 0.7709 - val_auc_32: 0.9786\n",
            "Epoch 17/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4818 - categorical_accuracy: 0.7750 - auc_32: 0.9798 - val_loss: 0.4987 - val_categorical_accuracy: 0.7700 - val_auc_32: 0.9785\n",
            "Epoch 18/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4806 - categorical_accuracy: 0.7754 - auc_32: 0.9799 - val_loss: 0.4974 - val_categorical_accuracy: 0.7698 - val_auc_32: 0.9785\n",
            "Epoch 19/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4794 - categorical_accuracy: 0.7760 - auc_32: 0.9800 - val_loss: 0.4997 - val_categorical_accuracy: 0.7695 - val_auc_32: 0.9784\n",
            "Epoch 20/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4785 - categorical_accuracy: 0.7756 - auc_32: 0.9801 - val_loss: 0.4966 - val_categorical_accuracy: 0.7710 - val_auc_32: 0.9787\n",
            "Epoch 21/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4775 - categorical_accuracy: 0.7766 - auc_32: 0.9801 - val_loss: 0.5004 - val_categorical_accuracy: 0.7686 - val_auc_32: 0.9783\n",
            "Epoch 22/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4770 - categorical_accuracy: 0.7769 - auc_32: 0.9802 - val_loss: 0.4952 - val_categorical_accuracy: 0.7731 - val_auc_32: 0.9788\n",
            "Epoch 23/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4760 - categorical_accuracy: 0.7768 - auc_32: 0.9802 - val_loss: 0.4959 - val_categorical_accuracy: 0.7713 - val_auc_32: 0.9785\n",
            "Epoch 24/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4754 - categorical_accuracy: 0.7767 - auc_32: 0.9803 - val_loss: 0.4981 - val_categorical_accuracy: 0.7718 - val_auc_32: 0.9785\n",
            "Epoch 25/40\n",
            "1839/1839 [==============================] - 9s 5ms/step - loss: 0.4744 - categorical_accuracy: 0.7779 - auc_32: 0.9804 - val_loss: 0.4965 - val_categorical_accuracy: 0.7714 - val_auc_32: 0.9787\n",
            "Epoch 26/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4736 - categorical_accuracy: 0.7781 - auc_32: 0.9804 - val_loss: 0.4984 - val_categorical_accuracy: 0.7704 - val_auc_32: 0.9785\n",
            "Epoch 27/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4731 - categorical_accuracy: 0.7780 - auc_32: 0.9805 - val_loss: 0.4976 - val_categorical_accuracy: 0.7730 - val_auc_32: 0.9786\n",
            "Epoch 28/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4727 - categorical_accuracy: 0.7783 - auc_32: 0.9805 - val_loss: 0.4982 - val_categorical_accuracy: 0.7735 - val_auc_32: 0.9784\n",
            "Epoch 29/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4722 - categorical_accuracy: 0.7783 - auc_32: 0.9806 - val_loss: 0.4982 - val_categorical_accuracy: 0.7730 - val_auc_32: 0.9785\n",
            "Epoch 30/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4715 - categorical_accuracy: 0.7786 - auc_32: 0.9806 - val_loss: 0.4962 - val_categorical_accuracy: 0.7722 - val_auc_32: 0.9786\n",
            "Epoch 31/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4709 - categorical_accuracy: 0.7786 - auc_32: 0.9806 - val_loss: 0.4962 - val_categorical_accuracy: 0.7722 - val_auc_32: 0.9787\n",
            "Epoch 32/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4706 - categorical_accuracy: 0.7789 - auc_32: 0.9807 - val_loss: 0.4969 - val_categorical_accuracy: 0.7732 - val_auc_32: 0.9787\n",
            "Epoch 33/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4703 - categorical_accuracy: 0.7789 - auc_32: 0.9806 - val_loss: 0.4988 - val_categorical_accuracy: 0.7702 - val_auc_32: 0.9784\n",
            "Epoch 34/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4693 - categorical_accuracy: 0.7794 - auc_32: 0.9808 - val_loss: 0.4984 - val_categorical_accuracy: 0.7713 - val_auc_32: 0.9786\n",
            "Epoch 35/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4695 - categorical_accuracy: 0.7796 - auc_32: 0.9807 - val_loss: 0.4992 - val_categorical_accuracy: 0.7730 - val_auc_32: 0.9785\n",
            "Epoch 36/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4690 - categorical_accuracy: 0.7796 - auc_32: 0.9808 - val_loss: 0.5002 - val_categorical_accuracy: 0.7706 - val_auc_32: 0.9783\n",
            "Epoch 37/40\n",
            "1839/1839 [==============================] - 8s 5ms/step - loss: 0.4687 - categorical_accuracy: 0.7798 - auc_32: 0.9808 - val_loss: 0.4994 - val_categorical_accuracy: 0.7722 - val_auc_32: 0.9784\n",
            "Epoch 38/40\n",
            "1839/1839 [==============================] - 8s 5ms/step - loss: 0.4684 - categorical_accuracy: 0.7795 - auc_32: 0.9808 - val_loss: 0.4997 - val_categorical_accuracy: 0.7724 - val_auc_32: 0.9783\n",
            "Epoch 39/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4676 - categorical_accuracy: 0.7798 - auc_32: 0.9809 - val_loss: 0.4977 - val_categorical_accuracy: 0.7724 - val_auc_32: 0.9786\n",
            "Epoch 40/40\n",
            "1839/1839 [==============================] - 8s 4ms/step - loss: 0.4676 - categorical_accuracy: 0.7805 - auc_32: 0.9809 - val_loss: 0.4994 - val_categorical_accuracy: 0.7710 - val_auc_32: 0.9786\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f402c25c0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on test data\n",
        "\n",
        "The model has an accuracy of 77.6% on the test data and a ROC AUC value of 0.979. The weighted f1-score for the model using the test data is 0.77.  "
      ],
      "metadata": {
        "id": "exF3bZmVrBk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save('')\n",
        "predictions = model.predict(X_test)\n",
        "predictions = np.argmax(predictions, axis = 1)\n",
        "loss, accuracy, auc = model.evaluate(X_test, y_test, verbose = 0, batch_size = 128)\n",
        "\n",
        "print(\"Test Accuracy: \", accuracy)\n",
        "print(\"Test ROC AUC: \", auc)\n",
        "\n",
        "\n",
        "\n",
        "y_true = np.argmax(y_test, axis = 1)\n",
        "\n",
        "print(\"Test F1 score(weighted): \", f1_score(y_true, predictions, average = 'weighted' ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8CcLt5-Z4Ql",
        "outputId": "72320900-d544-4d44-f1ff-16b0e917285a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1816/1816 [==============================] - 3s 1ms/step\n",
            "Test Accuracy:  0.776049017906189\n",
            "Test ROC AUC:  0.9788012504577637\n",
            "Test F1 score(weighted):  0.772326418682512\n"
          ]
        }
      ]
    }
  ]
}